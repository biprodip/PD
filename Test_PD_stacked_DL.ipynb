{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test PD stacked DL.ipynb",
      "provenance": [],
      "mount_file_id": "1x9LvsDSqKTQJrj_txjU4qfb2H1BQL1XP",
      "authorship_tag": "ABX9TyMIxTV2Y/UuljWD5xbobYNC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbL-ZnGGqfuC",
        "outputId": "20b14664-1e23-44a7-ddb9-ad69e70bb2d7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qblqTK65_NDn"
      },
      "source": [
        "# stacked generalization with neural net meta model on blobs dataset\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers.merge import concatenate\n",
        "from numpy import argmax\n",
        "from os import makedirs\n",
        "from keras.models import Sequential\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfFnwOlpLNg1"
      },
      "source": [
        "# Seed value\n",
        "# Apparently you may use different seed values at each stage\n",
        "seed_value= 0\n",
        "\n",
        "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(seed_value)\n",
        "# for later versions: \n",
        "# tf.compat.v1.set_random_seed(seed_value)\n",
        "\n",
        "# 5. Configure a new global `tensorflow` session\n",
        "from keras import backend as K\n",
        "#session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "#sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "#K.set_session(sess)\n",
        "# for later versions:\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "tf.compat.v1.keras.backend.set_session(sess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gacFBKX8iEXf"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import LeaveOneOut, GridSearchCV, KFold, train_test_split\n",
        "from sklearn import svm\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, matthews_corrcoef, roc_auc_score\n",
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxd9eKhiqiVl"
      },
      "source": [
        "pd_speech_features = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/PD Speech Features/gender_FG_v2.csv')\n",
        "pd_speech_features.head()\n",
        "print('The shape of the matrix is :', pd_speech_features.shape)\n",
        "#pd_speech_features['patient/healthy count'] = 1\n",
        "print(pd_speech_features['gender'].value_counts())\n",
        "pd_speech_features[['gender', 'class']] = pd_speech_features[['gender', 'class']].astype('category') #categoricals\n",
        "pd_speech_features.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yocURzHqncc"
      },
      "source": [
        "df=pd_speech_features\n",
        "train_df=df.values\n",
        "x=train_df[:,:-1]\n",
        "y=to_categorical(train_df[:,-1], num_classes=2)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x= sc.fit_transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNr-q1oFwEjv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29ba1018-3d30-41f2-903c-eb51524cdffd"
      },
      "source": [
        "#newly added\n",
        "kfold=KFold(10, shuffle=True, random_state=0)\n",
        "\n",
        "#no of individual models\n",
        "n_members = 3\n",
        "      \n",
        "acc=[]\n",
        "pr=[]\n",
        "rc=[]\n",
        "f1=[]\n",
        "auc=[]\n",
        "kappa=[]\n",
        "\n",
        "fold_count=0\n",
        "for trids,tstids in kfold.split(x):\n",
        "      fold_count=fold_count+1\n",
        "      trainX,testX=x[trids,:],x[tstids,:]\n",
        "      trainY,testY=y[trids,:],y[tstids,:]\n",
        "\n",
        "      #[samples, time steps, features]\n",
        "      n_features=trainX.shape[1]\n",
        "      trainX = np.array(trainX)\n",
        "      trainY = np.array(trainY)\n",
        "      testX = np.array(testX)\n",
        "      testY = np.array(testY)\n",
        "\n",
        "      print(trainX.shape)\n",
        "      print(trainY.shape)\n",
        "      print(testX.shape)\n",
        "      print(testY.shape)\n",
        "      \n",
        "      #makedirs('models')\n",
        "      \n",
        "      # load models\n",
        "      filename = '/content/drive/MyDrive/Colab Notebooks/PD Speech Features/models/ensemble_model_fold_'+ str(fold_count) +'.h5'\n",
        "      model = load_model(filename)\n",
        "      \n",
        "      [accr, precision, recall, f, a, k] = eval_model(model,testX,testY)\n",
        "      \n",
        "      acc.append(accr)\n",
        "      pr.append(precision)\n",
        "      rc.append(recall)\n",
        "      f1.append(f)\n",
        "      auc.append(a)\n",
        "      kappa.append(k)\n",
        "      \n",
        "      print(acc)\n",
        "      print(f1)\n",
        "      print(auc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(680, 71)\n",
            "(680, 2)\n",
            "(76, 71)\n",
            "(76, 2)\n",
            "Accuracy: 0.947368\n",
            "Precision: 0.982456\n",
            "Recall: 0.949153\n",
            "F1 score: 0.965517\n",
            "Cohens kappa: 0.854545\n",
            "ROC AUC: 0.992024\n",
            "[[16  1]\n",
            " [ 3 56]]\n",
            "[0.9473684210526315]\n",
            "[0.9655172413793103]\n",
            "[0.992023928215354]\n",
            "(680, 71)\n",
            "(680, 2)\n",
            "(76, 71)\n",
            "(76, 2)\n",
            "Accuracy: 0.934211\n",
            "Precision: 0.946429\n",
            "Recall: 0.963636\n",
            "F1 score: 0.954955\n",
            "Cohens kappa: 0.833040\n",
            "ROC AUC: 0.932684\n",
            "[[18  3]\n",
            " [ 2 53]]\n",
            "[0.9473684210526315, 0.9342105263157895]\n",
            "[0.9655172413793103, 0.9549549549549549]\n",
            "[0.992023928215354, 0.9326839826839827]\n",
            "(680, 71)\n",
            "(680, 2)\n",
            "(76, 71)\n",
            "(76, 2)\n",
            "Accuracy: 0.960526\n",
            "Precision: 0.965517\n",
            "Recall: 0.982456\n",
            "F1 score: 0.973913\n",
            "Cohens kappa: 0.892857\n",
            "ROC AUC: 0.989843\n",
            "[[17  2]\n",
            " [ 1 56]]\n",
            "[0.9473684210526315, 0.9342105263157895, 0.9605263157894737]\n",
            "[0.9655172413793103, 0.9549549549549549, 0.9739130434782608]\n",
            "[0.992023928215354, 0.9326839826839827, 0.989843028624192]\n",
            "(680, 71)\n",
            "(680, 2)\n",
            "(76, 71)\n",
            "(76, 2)\n",
            "Accuracy: 0.973684\n",
            "Precision: 0.969231\n",
            "Recall: 1.000000\n",
            "F1 score: 0.984375\n",
            "Cohens kappa: 0.901170\n",
            "ROC AUC: 0.964591\n",
            "[[11  2]\n",
            " [ 0 63]]\n",
            "[0.9473684210526315, 0.9342105263157895, 0.9605263157894737, 0.9736842105263158]\n",
            "[0.9655172413793103, 0.9549549549549549, 0.9739130434782608, 0.9843749999999999]\n",
            "[0.992023928215354, 0.9326839826839827, 0.989843028624192, 0.9645909645909646]\n",
            "(680, 71)\n",
            "(680, 2)\n",
            "(76, 71)\n",
            "(76, 2)\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f89c2f6f830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Accuracy: 1.000000\n",
            "Precision: 1.000000\n",
            "Recall: 1.000000\n",
            "F1 score: 1.000000\n",
            "Cohens kappa: 1.000000\n",
            "ROC AUC: 1.000000\n",
            "[[17  0]\n",
            " [ 0 59]]\n",
            "[0.9473684210526315, 0.9342105263157895, 0.9605263157894737, 0.9736842105263158, 1.0]\n",
            "[0.9655172413793103, 0.9549549549549549, 0.9739130434782608, 0.9843749999999999, 1.0]\n",
            "[0.992023928215354, 0.9326839826839827, 0.989843028624192, 0.9645909645909646, 1.0]\n",
            "(680, 71)\n",
            "(680, 2)\n",
            "(76, 71)\n",
            "(76, 2)\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f89c2c269e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Accuracy: 0.947368\n",
            "Precision: 0.964286\n",
            "Recall: 0.964286\n",
            "F1 score: 0.964286\n",
            "Cohens kappa: 0.864286\n",
            "ROC AUC: 0.989286\n",
            "[[18  2]\n",
            " [ 2 54]]\n",
            "[0.9473684210526315, 0.9342105263157895, 0.9605263157894737, 0.9736842105263158, 1.0, 0.9473684210526315]\n",
            "[0.9655172413793103, 0.9549549549549549, 0.9739130434782608, 0.9843749999999999, 1.0, 0.9642857142857143]\n",
            "[0.992023928215354, 0.9326839826839827, 0.989843028624192, 0.9645909645909646, 1.0, 0.9892857142857143]\n",
            "(681, 71)\n",
            "(681, 2)\n",
            "(75, 71)\n",
            "(75, 2)\n",
            "Accuracy: 0.960000\n",
            "Precision: 0.963636\n",
            "Recall: 0.981481\n",
            "F1 score: 0.972477\n",
            "Cohens kappa: 0.899329\n",
            "ROC AUC: 0.985891\n",
            "[[19  2]\n",
            " [ 1 53]]\n",
            "[0.9473684210526315, 0.9342105263157895, 0.9605263157894737, 0.9736842105263158, 1.0, 0.9473684210526315, 0.96]\n",
            "[0.9655172413793103, 0.9549549549549549, 0.9739130434782608, 0.9843749999999999, 1.0, 0.9642857142857143, 0.9724770642201834]\n",
            "[0.992023928215354, 0.9326839826839827, 0.989843028624192, 0.9645909645909646, 1.0, 0.9892857142857143, 0.9858906525573192]\n",
            "(681, 71)\n",
            "(681, 2)\n",
            "(75, 71)\n",
            "(75, 2)\n",
            "Accuracy: 0.933333\n",
            "Precision: 0.931034\n",
            "Recall: 0.981818\n",
            "F1 score: 0.955752\n",
            "Cohens kappa: 0.821002\n",
            "ROC AUC: 0.945455\n",
            "[[16  4]\n",
            " [ 1 54]]\n",
            "[0.9473684210526315, 0.9342105263157895, 0.9605263157894737, 0.9736842105263158, 1.0, 0.9473684210526315, 0.96, 0.9333333333333333]\n",
            "[0.9655172413793103, 0.9549549549549549, 0.9739130434782608, 0.9843749999999999, 1.0, 0.9642857142857143, 0.9724770642201834, 0.9557522123893805]\n",
            "[0.992023928215354, 0.9326839826839827, 0.989843028624192, 0.9645909645909646, 1.0, 0.9892857142857143, 0.9858906525573192, 0.9454545454545455]\n",
            "(681, 71)\n",
            "(681, 2)\n",
            "(75, 71)\n",
            "(75, 2)\n",
            "Accuracy: 0.933333\n",
            "Precision: 0.927273\n",
            "Recall: 0.980769\n",
            "F1 score: 0.953271\n",
            "Cohens kappa: 0.837310\n",
            "ROC AUC: 0.958194\n",
            "[[19  4]\n",
            " [ 1 51]]\n",
            "[0.9473684210526315, 0.9342105263157895, 0.9605263157894737, 0.9736842105263158, 1.0, 0.9473684210526315, 0.96, 0.9333333333333333, 0.9333333333333333]\n",
            "[0.9655172413793103, 0.9549549549549549, 0.9739130434782608, 0.9843749999999999, 1.0, 0.9642857142857143, 0.9724770642201834, 0.9557522123893805, 0.9532710280373831]\n",
            "[0.992023928215354, 0.9326839826839827, 0.989843028624192, 0.9645909645909646, 1.0, 0.9892857142857143, 0.9858906525573192, 0.9454545454545455, 0.9581939799331103]\n",
            "(681, 71)\n",
            "(681, 2)\n",
            "(75, 71)\n",
            "(75, 2)\n",
            "Accuracy: 0.920000\n",
            "Precision: 0.928571\n",
            "Recall: 0.962963\n",
            "F1 score: 0.945455\n",
            "Cohens kappa: 0.795640\n",
            "ROC AUC: 0.957672\n",
            "[[17  4]\n",
            " [ 2 52]]\n",
            "[0.9473684210526315, 0.9342105263157895, 0.9605263157894737, 0.9736842105263158, 1.0, 0.9473684210526315, 0.96, 0.9333333333333333, 0.9333333333333333, 0.92]\n",
            "[0.9655172413793103, 0.9549549549549549, 0.9739130434782608, 0.9843749999999999, 1.0, 0.9642857142857143, 0.9724770642201834, 0.9557522123893805, 0.9532710280373831, 0.9454545454545454]\n",
            "[0.992023928215354, 0.9326839826839827, 0.989843028624192, 0.9645909645909646, 1.0, 0.9892857142857143, 0.9858906525573192, 0.9454545454545455, 0.9581939799331103, 0.9576719576719577]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_CXmdl8Ae_W",
        "outputId": "817523a0-87c6-46b7-fc59-f84f897b203d"
      },
      "source": [
        "from statistics import mean\n",
        "print('acc: %f',mean(acc))\n",
        "print('f1: %f',mean(f1))\n",
        "print('auc: %f',mean(auc))\n",
        "print('pr: %f',mean(pr))\n",
        "print('rc: %f',mean(rc))\n",
        "print('kappa: %f',mean(kappa))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc: %f 0.9509824561403508\n",
            "f1: %f 0.9670000804199732\n",
            "auc: %f 0.9715638754017141\n",
            "pr: %f 0.9578433438914382\n",
            "rc: %f 0.9766562617677693\n",
            "kappa: %f 0.8699180852484752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH79HdNB5Sb-"
      },
      "source": [
        "def eval_model(model,testX,testY):\n",
        "   # predict probabilities for test set\n",
        "   y_prob = predict_stacked_model(model, testX)\n",
        "   # predict crisp classes for test set\n",
        "   y_classes=np.argmax(y_prob,axis=1)\n",
        "   act_Y=np.argmax(testY,axis=1)\n",
        "   \n",
        "   # accuracy: (tp + tn) / (p + n)\n",
        "   accuracy = accuracy_score(act_Y, y_classes)\n",
        "   print('Accuracy: %f' % accuracy)\n",
        "   # precision tp / (tp + fp)\n",
        "   precision = precision_score(act_Y, y_classes)\n",
        "   print('Precision: %f' % precision)\n",
        "   # recall: tp / (tp + fn)\n",
        "   recall = recall_score(act_Y, y_classes)\n",
        "   print('Recall: %f' % recall)\n",
        "   # f1: 2 tp / (2 tp + fp + fn)\n",
        "   f1 = f1_score(act_Y, y_classes)\n",
        "   print('F1 score: %f' % f1)\n",
        " \n",
        "   # kappa\n",
        "   kappa = cohen_kappa_score(act_Y, y_classes)\n",
        "   print('Cohens kappa: %f' % kappa)\n",
        "   # ROC AUC\n",
        "   auc = roc_auc_score(testY, y_prob)\n",
        "   print('ROC AUC: %f' % auc)\n",
        "   # confusion matrix\n",
        "   matrix = confusion_matrix(act_Y, y_classes)\n",
        "   print(matrix)\n",
        "   \n",
        "   return [accuracy, precision, recall, f1, auc, kappa]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5kY2jQRSYA_"
      },
      "source": [
        "# make a prediction with a stacked model\n",
        "def predict_stacked_model(model, inputX):\n",
        "\t# prepare input data\n",
        "\tX = [inputX for _ in range(len(model.input))]\n",
        "\t# make prediction\n",
        "\treturn model.predict(X, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}